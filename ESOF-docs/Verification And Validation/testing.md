4. Software Testing
===================

Software testing is an investigation conducted to provide stakeholders with information about the quality of the product or service under test. Software testing can also provide an objective, independent view of the software to allow the business to appreciate and understand the risks of software implementation. Test techniques include the process of executing a program or application with the intent of finding software bugs.

Software testing involves the execution of a software component or system component to evaluate one or more properties of interest. In general, these properties indicate the extent to which the component or system under test:
* Meets the requirements that guided its design and development;
* Responds correctly to all kinds of inputs;
* Performs its functions within an acceptable time:
* Is sufficiently usable;
* Can be installed and run in its intended environments; 
* Achieves the general result its stakeholders desire.

Software has attached some factors that determinate the quality of itself. Factors like **functionality**, **efficiency**, **portability**, **usability**, **reliability** and **maintainability**.

To evaluate the software quality, we used several types of tests, **unit tests** for testing all functions/classes individually; **integration tests** for testing a group of components combination during they're process; **functional tests** for testing if the software works in different environments; **performance testing** for testing the speed and efficiency software; **usability testing** for testing how the GUI is easy to use to the clients and **acceptance testing** for ensure that de delivered product meets the requirements and works as the customer expected.

In Software engineering, software project management and software testing, we usually answer to this two questions: "Are we building the right product?" and "Are we buildind the product right?". Well, we answer to the first question to reflect about the software **validation**, and the second  about **verification**. Software verification ensures that the product has been built according to the requirements and design specifications, while software validation ensures that the product actually meets the user's needs, and that the specifications were correct in the first place. Software verification ensures that "you built it right". Software validation ensures that "you built the right thing". Software validation confirms that the product, as provided, will fulfill its intended use.

##4.1. How is Django-CMS tested?

As we mentioned in some [chapters before](https://github.com/SofiaReis/django-cms/blob/develop/ESOF-docs/Requirements%20elicitation/requirements.md#21-issues-on-django-cms), Django-CMS it's really restrict about tests. To contribute to the plataform, you have to attach tests mandatorily. According Django-CMS, tests should be **unitary**, should test as much as possible only one function or class; **short running** and **easy to understand**. If you are a developer, you use Django-CMS and want to write and run tests, you can see how to do that in [here](http://docs.django-cms.org/en/latest/contributing/testing.html).

To test Django-CMS, the main core developers established some programs to use in the test process that you can consult in [here](https://github.com/divio/django-cms/blob/develop/test_requirements/requirements_base.txt). The most important packages/programs used for testing Django-CMS are:
>- **Coverage:** It's a python package and measures code average, typically during test execution. Coverage uses the code analysis tools and tracing hooks provided in the Python standard library to determine which lines are executable, and which have been executed. (We use coverage mainly for make report in point 4.3)
>- **Coveralls:** Service to publish your coverage stats online with a lot of nice features. This package provides seamless integration with coverage.py in your python projects. It makes custom report for data generated by coverage.py package and sends it to json API of coveralls.io service. This package works with any CI (continuous integration) environment. But Django-CMS uses [Travis for CI](https://travis-ci.org/divio/django-cms) to integrate code into a shared repository several times a day. Each check-in is then verified by an automated build, allowing teams to detect problems early. By integrating regularly, you can detect errors quickly, and locate them more easily. 
>- **Unittest-xml-reporting:** It's a unittest test runner that can save test results to XML files that can be consumed by a wide range of tools, such as build systems, IDEs and continuous integration servers.
>- **Selenium:** It automates browsers. It's a software testing framework for web applications. Selenium provides a record/playback tool for authoring tests without learning a test scripting language (Selenium IDE). The tests can be run against most modern web browsers.
>- **Django-debug-toolbar:** A configurable set of panels that display various debug information about the current request/response.
>- **Django-better-test:** A better test command for Django. Allows you to use --parallel to run tests in parallel (distributed as evenly as possible across your CPU cores) and --isolate to run each test in a separate process to detect test that leak state. You can also quickly re-run the tests failed in the last run using --failed.
>- **Pyflakes:** A simple program which checks Python source files for errors. Pyflakes analyzes programs and detects various errors. It works by parsing the source file, not importing it, so it is safe to use on modules with side effects. It’s also much faster.

After discover what tools Django-CMS uses to test the software, we decide to study the software testability, i.e. the ease with which a program can be tested. Well, after make some tests and explore the git repository we made this conclusions about the factors that determinate the software testability:

- **Controllability:** It's impossible to access Components Under Test (CUT) with the given test suite. In Django-CMS, they don't do tests while run time. 
 
- **Observability:**  Well explicit. Information about what module is being tested and even a traceback will be displayed in the console with appropriate and noticeable separation. In the end of the test run a compilation of final results (mostly statistical) will also be displayed.
 
- **Isolateability:** It is possible to run tests on a specific module by adding module name as the last argument when running the test suite. One can also state the directory where the specific tests one wants to run are stored.
 
- **Separation of concerns:** Altough the current test name is displayed it may sometimes not suffice to properly identify what is being tested but mostly the tests have a good separation of concerns given that they are as unitary as possible. As a matter of fact, Django's creators themselves clearly specify in the documentation that:
> **Generally tests should be:**
>    Unitary (as much as possible). i.e. should test as much as possible only one function/method/class. That’s the very definition of unit tests. Integration tests are interesting too obviously, but require more time to maintain since they have a higher probability of breaking.
And they seem to follow their own advices.

- **Understandability:** As stated, altough sometimes test names alone are not enough to accurately identify what component exactly is being tested, it is also displayed which test exactly is being ran so a quick peek on the test code - only in the few cases of need for clarification - should be enough to fully understand the running test.

- **Heterogeneity:** The most recent test suite for Django-cms includes diverse tools such selenium (http://www.seleniumhq.org/), sphinx (http://sphinx-doc.org/), pyenchant(http://pythonhosted.org/pyenchant/) and others as specified in https://github.com/SofiaReis/django-cms/blob/develop/test_requirements/requirements_base.txt but as some tools are purely aesthetic the main testing tool would be Selenium.

##4.2. How to improve software testability?

It's really important to try every day improve the software testability and make the most perfect product possible. A software tested, it's a software with quality. Doing tests helps to prove if the software requirements are implemented correctly/uncorrectly; Detect defects and ensure that testing is before inclusion in the main repository, to prevent fatal erros and serious problems. Testing also desmonstrates that the program is working equal to the specification and requirements. It's also important test in different environments to verify proper integration with all the system components.

Well, to improve the this crucial component we think is crucial:
* **Understandability:** Improve the command interface to turn possible see what happens in every test file during the test runtime. 
* **Isolateability:** Make a list of possible unit-tests, and allow to run only one and see the report.

In general, they already use powerfull tools for software testing, they have to work hardly in the coverage increase. It's really important have an "healthy" code.  

##4.3. Tests Statistics

We made some studies about the Django-CMS tests statics, like how many unit tests are used, code coverage, system and performance.
About the unit-tests, we found in the git repository two folders named [test_utils](https://github.com/SofiaReis/django-cms/tree/develop/cms/test_utils) and [tests](https://github.com/SofiaReis/django-cms/tree/develop/cms/tests) with some unit-tests. In the picture bellow, we can see that are made 844 tests to the software during 331.361 segundos.

![](https://github.com/SofiaReis/django-cms/blob/develop/ESOF-docs/Verification%20And%20Validation/runtime.png?raw=true)

Now, about coverage... Django-CMS uses Coverage python package to calculate the degree to which the source code of a program is tested by a particular test suite. It's a code reviewing tool that provides information that helps to see which code has not been tested. Through coverage it's possible rethink the test suite, test strategy, system design and construct new pull requests for the untested parts. After running coverage in the Django-CMS, we consulted the generated [report](https://github.com/SofiaReis/django-cms/blob/develop/ESOF-docs/Verification%20And%20Validation/tests.txt) where you can see the report shows the count of executable statements (Stmts), the number of those statements missed (Miss), and the resulting coverage, expressed as a percentage (Cover). We get a total code coverage of 28% which is a low value. Despite of Django-CMS require tests for all pull requests, it's obvious that they have just 28% of the code tested. It's bad, after explore the repository we think that they started to be persistent with tests just some months ago. Maybe in the beginnig test were not really made but now they're making this a tests a big thing. You can consult the coverage [HTML results](https://github.com/SofiaReis/django-cms/tree/develop/ESOF-docs/Verification%20And%20Validation/coverage). 

Django-CMS as a framework that provides front-end changes has a low initialization time. It's very quickly. But the load of the website it will depend of the pages content (pictures and animations, for example).
